# 深度学习分类实战系列

[toc]

**github代码地址：**[传送门](https://github.com/kingqiuol/pytorch-template.git)

# CIFAR100分类实战系列之基本技巧

## 一、任务分析

### 1.1、CIFAR-100 数据集简介

首先，我们需要拿到数据和明确我们的任务。这里以cifar-100为例，它是8000万个微小图像数据集的子集，他们由Alex Krizhevsky，Vinod Nair和Geoffrey Hinton收集。CIFAR **-100**数据集（100 个类别）是 Tiny Images 数据集的子集，由 60000 个 32x32 彩色图像组成。CIFAR-100 中的 100 个类分为 20 个超类。每个类有 600 张图像。每个图像都带有一个“精细”标签（它所属的类）和一个“粗略”标签（它所属的超类）。每个类有 500 个训练图像和 100 个测试图像。

简单来说，我们需要针对CIFAR-100 数据集，设计、搭建、训练机器学习模型，能够尽可能准确地分辨出测试数据地标签。

### 1.2、整体思路

本次任务我们使用了开源的深度卷积神经网络作为我们的baseline backone, 同时通过消融实验，设计数据增强方法。经过实验调优以及对比不同模型来选择最优模型。

#### 1.2.1、baseline选择

考虑到本次任务的原始数据分辨率小(32x32),过深过大的网络可能会导致发生过拟合(overfiting)现象，我们选择了一个参数量较少的深度模型resnet50作为此次的baseline backbone。

#### 1.2.2、数据增强

初始数据增强方面我们主要选择：随机翻转、随机剪切以及随机旋转等增强方法进行实验。

>**数据均值和方差的计算**
>
>在很多时候，我们进行归一化时需要计算均值和方差进行归一化。这时我们不能直接使用现有模型的均值和方差，因为我们自己的数据和别人的不一样。代码如下：
>
>```python
>import numpy
>def compute_mean_std_v2(cifar100_dataset):
>    """compute the mean and std of cifar100 dataset
>    Args:
>        cifar100_training_dataset or cifar100_test_dataset
>        witch derived from class torch.utils.data
>
>    Returns:
>        a tuple contains mean, std value of entire dataset
>    """
>
>    data_r = numpy.dstack([cifar100_dataset[i][1][:, :, 0] for i in range(len(cifar100_dataset))])
>    data_g = numpy.dstack([cifar100_dataset[i][1][:, :, 1] for i in range(len(cifar100_dataset))])
>    data_b = numpy.dstack([cifar100_dataset[i][1][:, :, 2] for i in range(len(cifar100_dataset))])
>    mean = numpy.mean(data_r), numpy.mean(data_g), numpy.mean(data_b)
>    std = numpy.std(data_r), numpy.std(data_g), numpy.std(data_b)
>
>    return mean, std
>```

#### 1.2.3、参数调优

* 优化器选择

​		我们初步选择**SGD**作为优化器

* 学习率选择

​		我们通过枚举不同学习率下的loss值选择最优学习率，绘制曲线如下：

<img src="C:\Users\Administrator\Desktop\pytorch-template\doc\find_lr.jpg" alt="find_lr" style="zoom:67%;" />

​		通过观察可知，**lr=0.1**时loss最低，此时学习率最优。

* batch size的选择

​		考虑到训练时间和机器性能，我们使用128batch size

* 输入图像大小的选择 
原则上图像分辨率高对网络识别的效果越好，但是由于机器性能和训练时间限制，我们选择32x32大小的分辨率
* 迭代epoch选择
初始设置200个epoch

## 二、初步训练

初步训练的目的是为了观察我们的模型能否拟合数据。最终结果如下：

| network  | params | top1 err | top5 err | acc  | **mAP** | total epoch |
| :------: | :----: | :------: | :------: | :--: | :-----: | :---------: |
| resnet50 |  90.7  |   0.21   |  0.0555  | 0.78 |  0.84   |     200     |

可以看出，我们的模型能够拟合数据，准确率达到78%，那么接下来就是要如何提升模型的准确率了。

### 2.1、模型评估

当然，光从准确率不能完全评估模型的性能，我还需要从混淆矩阵来看每一类的分类情况，PR曲线分析我们模型的准确率和召回率，ROC曲线评估模型的泛化能力

* 混淆矩阵

<img src="C:\Users\Administrator\Desktop\pytorch-template\doc\CIFAR100_cm.jpg" alt="CIFAR100_cm" style="zoom:67%;" />

通过观察，可以看出模型对每一类都能很好的进行分类。

* PR曲线

<img src="C:\Users\Administrator\Desktop\pytorch-template\doc\pr_curve.jpg" alt="pr_curve" style="zoom:67%;" />

* ROC曲线

<img src="C:\Users\Administrator\Desktop\pytorch-template\doc\roc.jpg" alt="roc" style="zoom:67%;" />

## 三、其他baseline backone

我们初步训练resnet50作为基础模型，当然这是不够的。我们还需要更多的基本模型做对比，依次来选择更好的模型，本文实验的模型如下：

|  network   | params | top1 err | top5 err | acc  | **mAP** | total epoch |
| :--------: | :----: | :------: | :------: | :--: | :-----: | :---------: |
|  resnet18  |  42.8  |   0.24   |  0.0716  | 0.75 |  0.78   |     200     |
|  resnet50  |  90.7  |   0.21   |  0.0555  | 0.78 |  0.84   |     200     |
| resnet101  |  163   |   0.21   |  0.0552  | 0.79 |  0.84   |     200     |
| resnext50  |   50   |   0.22   |   0.06   | 0.77 |  0.83   |     200     |
| resnext101 |   68   |   0.22   |  0.059   | 0.78 |  0.84   |     200     |
| wideresnet |  130   |   0.21   |   0.05   | 0.8  |  0.84   |     200     |

# CIFAR100分类实战系列之数据！数据！数据！

## 一、数据增强

数据增强是解决过拟合一个比较好的手段，它的本质是在一定程度上扩充训练数据样本，避免模型拟合到训练集中的噪声，所以设计一个好的数据增强方案尤为必要。在CV任务中，常用的数据增强包括RandomCrop(随机扣取)、Padding(补丁)、RandomHorizontalFlip(随机水平翻转)、ColorJilter(颜色抖动)等。还有一些其他高级的数据增强技巧，比如RandomEreasing(随机擦除)、MixUp、CutMix、AutoAugment，以及最新的AugMix和GridMask等。在此次任务中我们通过实验对比，选择了一个较合适的数据增强方案。